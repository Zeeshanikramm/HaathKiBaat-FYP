{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNEqwGzTPgDW",
        "outputId": "9b030460-6c62-4402-ff2c-bde949b84eb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1TdfOz-MVrA_XP8h8oXd8IBTvOXwbFN1Y into /content/data.zip... Done.\n",
            "Unzipping..."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/google_drive_downloader/google_drive_downloader.py:78: UserWarning: Ignoring `unzip` since \"1TdfOz-MVrA_XP8h8oXd8IBTvOXwbFN1Y\" does not look like a valid zip file\n",
            "  warnings.warn('Ignoring `unzip` since \"{}\" does not look like a valid zip file'.format(file_id))\n"
          ]
        }
      ],
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1TdfOz-MVrA_XP8h8oXd8IBTvOXwbFN1Y',\n",
        "                                    dest_path='/content/data.zip',\n",
        "                                    unzip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfdq8bSO7s0a"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "import os\n",
        "from tqdm.autonotebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import cv2\n",
        "import sys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFDscTBfPNt1",
        "outputId": "c8b27e71-16ba-4631-84d5-ecd1ee8f150d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n",
            "Cloning into 'SignLanguageClassification'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 5 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (5/5), done.\n",
            "/content/SignLanguageClassification\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__) \n",
        "!git clone https://github.com/Zeeshanikramm/SignLanguageClassification.git\n",
        "%cd SignLanguageClassification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCCa-GwofjZb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBMVWVfxuIPi",
        "outputId": "9bc9506f-824e-410b-a76b-a097b36aa012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__TVncCdN1jN",
        "outputId": "928577cd-216a-4486-cc52-9664fe0e94f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "345\n",
            "خ\n",
            "د\n",
            "ڈ\n",
            "ذ\n",
            "ر\n",
            "ز\n",
            "ڑ\n",
            "ژ\n",
            "س\n",
            "ش\n",
            "ض\n",
            "ص\n",
            "ط\n",
            "ظ\n",
            "ع\n",
            "غ\n",
            "ف\n",
            "ق\n",
            "ک\n",
            "گ\n",
            "م\n",
            "ل\n",
            "ن\n",
            "ہ\n",
            "ھ\n",
            "و\n",
            "ے\n",
            "ء\n",
            "ی\n",
            "ا\n",
            "آ\n",
            "ب\n",
            "پ\n",
            "ت\n",
            "ج\n",
            "ث\n",
            "ح\n",
            "چ\n",
            "کھانا\n",
            "کاٹنا\n",
            "کپڑے پہننا\n",
            "کھرچنا\n",
            "کھڑا ہونا\n",
            "کہنا\n",
            "کھینچنا\n",
            "لینا\n",
            "مدد کرنا\n",
            "معاف کرنا\n",
            "معذرت کرنا\n",
            "ملاقات کا وقت لیجیے\n",
            "نگلنا\n",
            "ورزش کرنا\n",
            "واضح کرنا\n",
            "ہنسنا\n",
            "وعدہ\n",
            "اٹھنا\n",
            "آرام\n",
            "اشارہ کرنا\n",
            "بات چیت\n",
            "بچانا\n",
            "باہر جانا\n",
            "بھاگنا\n",
            "بھولنا\n",
            "پوچھنا\n",
            "بولنا\n",
            "بیٹھنا\n",
            "پینا\n",
            "خراش لگنا\n",
            "خون بہنا\n",
            "درست کرنا\n",
            "دکھانا\n",
            "دھکا دینا\n",
            "دورہ کرنا\n",
            "دیکھنا\n",
            "دینا\n",
            "ڈھونڈنا\n",
            "روکنا\n",
            "رابطہ کرنا\n",
            "رکھنا\n",
            "رونا\n",
            "زخمی\n",
            "سانس لینا\n",
            "سننا\n",
            "سونا\n",
            "السلام وعلیکم\n",
            "ادھر آو\n",
            "آپ کیسے ہیں؟\n",
            "ایک اچھا دن گزاریں\n",
            "اچھا\n",
            "ایمبولینس کو کال کریں\n",
            "خبر دار\n",
            "خدا حافظ\n",
            "دروازہ بند کرو\n",
            "دپہر کا سلام\n",
            "شام بخیر\n",
            "شب بخیر\n",
            "مبارک ہو\n",
            "عید مبارک\n",
            "صبح بخیر\n",
            "معاف کیجئے گا\n",
            "میں آپ کی کیسے مدد کر سکتا ہوں؟\n",
            "نیا سال مبارک ہو\n",
            "چلے جاؤ\n",
            "کبھی مجھ سے ملنے آو\n",
            "چھونا مت\n",
            "کھڑکی بند کرو\n",
            "کوئی بات نہیں\n",
            "کیا آپ اسکول جاتے ہیں؟\n",
            "کیا آپ انگریزی بول سکتے ہیں؟\n",
            "کیا آپ ایک سماعت کی مدد لیتے ہیں؟\n",
            "کیا آپ تیار ہیں؟\n",
            "کیا آپ کے پاس کوئی اسپرین ہے؟\n",
            "کیا تم بالکل ٹھیک محسوس کرتے ہو؟\n",
            "کیا تم بھوکے ہو؟\n",
            "کیا تم بہرے ہو؟\n",
            "کیا تم سمجھے؟\n",
            "کیا تم نے اس سے پوچھا؟\n",
            "کیا تم نے کھا یا؟\n",
            "کیا تم نے کھا لیا ہے؟\n",
            "کیا میں اپ کی مدد کر سکتا ہوں؟\n",
            "کیا میں ٹوائلٹ استعمال کر سکتا ہوں؟\n",
            "ہیلو\n",
            "بہت اچھا\n",
            "جی ہاں\n",
            "خوش آمدید\n",
            "کب؟\n",
            "کس کا؟\n",
            "کس لئے؟\n",
            "کس کے ساتھ؟\n",
            "کہاں؟\n",
            "کون؟\n",
            "کونسا؟\n",
            "کیا؟\n",
            "کیوں؟\n",
            "وعلیکم السلام\n",
            "واہ\n",
            "یہ بہت اہم ہے\n",
            "آپ کا نام کیا ہے؟\n",
            "آپ کا ٹیلیفون نمبر کیا ہے؟\n",
            "آپ کہاں رہتے ہیں؟\n",
            "اس کے لئے کوئی اشارہ نہیں ہے\n",
            "ایک حادثہ ہوا ہے\n",
            "آپ سے مل کر خوشی ہوئی\n",
            "اپ کیسا محسوس کر رہے ہیں؟\n",
            "بعد میں ملتے ہیں\n",
            "براہ مہربانی\n",
            "شاید\n",
            "کتنا؟\n",
            "شکریہ\n",
            "کتنی دور؟\n",
            "کتنی دیر\n",
            "کتنی مرتبہ؟\n",
            "کتنے؟\n",
            "کیسے؟\n",
            "مجھے آپ پر یقین نہیں\n",
            "مجھے یہ پسند نہیں\n",
            "میرا ایک سوال ہے\n",
            "میرا نام ۔ ۔ ۔ ۔ ۔ ہے۔\n",
            "میں اپ سے بعد میں ملتا ہوں\n",
            "میں اشاروں کی زبان سیکھ رہا ہوں\n",
            "میں ایک طالب علم ہوں\n",
            "میں بہرا پیدا ہوا تھا\n",
            "میں تھوڑا سا بولتا ہوں\n",
            "میں جلد ہی واپس آؤں گا\n",
            "میں نہیں سمجھا\n",
            "نہیں\n",
            "اسپرین\n",
            "ایتھلیٹس فٹ\n",
            "انیمیا\n",
            "الرجی\n",
            "ايڈز\n",
            "اینٹی بایوٹک\n",
            "دانہ\n",
            "دمہ\n",
            "سانس کا شدید انفیکشن\n",
            "عادت\n",
            "گٹھیا\n",
            "علم سماعت\n",
            "قطع عضو\n",
            "آٹزم\n",
            "نشہ آور اشیا۶\n",
            "جسم کی بو\n",
            "جسيمہ شماری\n",
            "چھالا\n",
            "چوٹ\n",
            "حیاتیاتی\n",
            "خون کا سامپل\n",
            "متاوازن غذا\n",
            "برانکائیٹس\n",
            "بروفن\n",
            "بستر پر آرام\n",
            "بلڈ پریشر\n",
            "بیکٹیریا\n",
            "کلینک\n",
            "غذا\n",
            "کیپسول\n",
            "کیموتیریپی\n",
            "کمی\n",
            "کینسر\n",
            "معزوری\n",
            "مقررہ تاریخ\n",
            "کھانسی\n",
            "لگنے والی\n",
            "بہرہ پن\n",
            "نفسیاتی دباو\n",
            "تشويش ناک\n",
            "ہيضہ\n",
            "تکلیف دہ\n",
            "چکن پاکس\n",
            "خوراک\n",
            "ڈاؤن سنڈروم\n",
            "ڈس انفیکٹ\n",
            "ذیابیطیس\n",
            "سی پی آر\n",
            "روئی\n",
            "ایگزیما\n",
            "ایمرجنسی روم\n",
            "بخار\n",
            "ایدھی فاؤنڈیشن\n",
            "آنکھوں کے قطرے\n",
            "بے ہوش ہونا\n",
            "ای این ٹی\n",
            "ہڈی ٹوٹنا\n",
            "کان کے قطرے\n",
            "فلو\n",
            "معائنہ\n",
            "کان کا درد\n",
            "وبائی مرض\n",
            "قریب کی نظر کی کمزوری\n",
            "انہیلر\n",
            "بے خوابی\n",
            "انفیکشن\n",
            "سر درد\n",
            "آئی سی یو\n",
            "ایچ آئی وی\n",
            "سوزش\n",
            "سینے میں جلن\n",
            "انسولین\n",
            "صحت\n",
            "ہیلتھ انشورنس\n",
            "گائناکولوجی\n",
            "فولاد\n",
            "ماہر امراض نسواں\n",
            "ڈرپ\n",
            "ٹیکہ\n",
            "ہسپتال\n",
            "گٹلی\n",
            "مدافعتی نظام\n",
            "ہیپاٹائیٹس\n",
            "آکسیجن ماسک\n",
            "آپریشن کرنا\n",
            "دوا\n",
            "آدھے سر کا درد\n",
            "ایم آر آئی\n",
            "دماغی بیماری\n",
            "آپریشن\n",
            "جوشاندہ\n",
            "آپريشن کا کمرہ\n",
            "خسرہ\n",
            "موٹاپا\n",
            "سوئی\n",
            "زچگی وارڈ\n",
            "مرہم\n",
            "لیبر\n",
            "غذائیت کی کمی\n",
            "ملیریا\n",
            "متلی\n",
            "نیورالوجی\n",
            "دور کی نظر کی کمزوری\n",
            "پیلیا\n",
            "گردوں کی پتری\n",
            "علم نفسیات\n",
            "فعلیاتی\n",
            "طب نفسیات\n",
            "پروٹین\n",
            "فالج\n",
            "پائیلز\n",
            "فزیکل تھیرپی\n",
            "پیناڈول\n",
            "ڈاکٹری نسخہ\n",
            "پیڈیاٹرک\n",
            "گولی\n",
            "پیسمیکر\n",
            "ریسکیو 1122\n",
            "قرنطینہ\n",
            "ریڈیو تھیرپی\n",
            "ریش\n",
            "ریبیز\n",
            "خارش\n",
            "سٹروک\n",
            "اسپیچ تھیراپی\n",
            "بیمار\n",
            "جراثیم سے پاک کرنا\n",
            "اسٹریچر\n",
            "بیماری\n",
            "سرجری\n",
            "سرنج\n",
            "سمال پاکس\n",
            "موچ\n",
            "گلے آنا\n",
            "صفائی\n",
            "ماہر\n",
            "مجموعہ علامات\n",
            "ٹانکا\n",
            "پیٹ کا درد\n",
            "علامت\n",
            "ٹائیفائیڈ\n",
            "تھیراپی\n",
            "دانتوں کا درد\n",
            "ٹی بی\n",
            "تھرمامیڑ\n",
            "تشنج\n",
            "رسولی\n",
            "ٹرانسپلانٹ\n",
            "ویکسین\n",
            "الٹراساؤنڈ\n",
            "ایکس رے\n",
            "ویل چیئر\n",
            "الٹی\n",
            "وائرس\n",
            "خون کے سفید خلیات\n",
            "ویکسینیشن\n",
            "وٹامن\n",
            "عالمی ادارہ صحت\n",
            "کمزور ہڈیاں\n",
            "پیشاب کا نمونہ\n",
            "کالی کھا نسی\n",
            "نمونیا\n",
            "معائنہ خون\n",
            "مرگی\n",
            "مسکرانا\n",
            "مصنوعی بے ہوشی\n",
            "ابتدائ طبی امداد\n",
            "مرہم پٹی\n",
            "غذائی زہريت\n",
            "پھپھوندی\n",
            "ابتدائی طبی امداد کا باکس\n",
            "درد سينہ\n",
            "قبول کرنا\n",
            "اتفاق کرنا\n",
            "جسم میں پانی کی کمی\n",
            "اندھا پن\n",
            "پیدائش\n",
            "خون کا گروپ\n",
            "دل کا دورہ \n"
          ]
        }
      ],
      "source": [
        "asd=[1,2,3,4,5,6]\n",
        "\n",
        "#Label file:\n",
        "data_path ='/content/drive/MyDrive/signOutput'\n",
        "classes = os.listdir(data_path)\n",
        "print(len(classes))\n",
        "\n",
        "for i in range(len(classes)):\n",
        "  print(classes[i])\n",
        "decoder = {}\n",
        "for i in range(len(classes)):\n",
        "    decoder[classes[i]] = i\n",
        "encoder = {}\n",
        "for i in range(len(classes)):\n",
        "    encoder[i] = classes[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiuCb0FPCn87"
      },
      "outputs": [],
      "source": [
        "id = list()\n",
        "path = '/content/drive/MyDrive/signOutput'\n",
        "for i in os.listdir(path):\n",
        "  p1 = os.path.join(path,i)\n",
        "  for j in os.listdir(p1):\n",
        "    p2 = os.path.join(p1,j)\n",
        "    id.append((i,p2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5iUVP4p6VFn"
      },
      "outputs": [],
      "source": [
        "class video_dataset(Dataset):\n",
        "    def __init__(self,frame_list,sequence_length = 16,transform = None):\n",
        "        self.frame_list = frame_list\n",
        "        self.transform = transform\n",
        "        self.sequence_length = sequence_length\n",
        "    def __len__(self):\n",
        "        return len(self.frame_list)\n",
        "    def __getitem__(self,idx):\n",
        "        label,path = self.frame_list[idx]\n",
        "        # print(\"Path is \",path)\n",
        "        # print(\"label is \", label)\n",
        "        list_of_imgs_dir=os.listdir(path)\n",
        "\n",
        "        \n",
        "        count=0\n",
        "        seq_img = list()\n",
        "        for i in range(12):   # CHANGING for i in range(16): to for i in range(6): -----> now 3\n",
        "            #print(list_of_imgs_dir[0:8], \"   The 0th is \" , list_of_imgs_dir[0] )\n",
        "            try:\n",
        "              count=count+1\n",
        "              img = cv2.imread(path+\"/\"+list_of_imgs_dir[0])\n",
        "              # print(\"--------\")\n",
        "              list_of_imgs_dir.pop(0)\n",
        "              img1 = img[:,:,:]\n",
        "              #cv2.imshow(\"img1\",img1)\n",
        "              if(self.transform):\n",
        "                img1 = self.transform(Image.fromarray(img))\n",
        "              seq_img.append(img1)\n",
        "            except:\n",
        "              break\n",
        "        seq_image = torch.stack(seq_img)\n",
        "        seq_image = seq_image.reshape(3,12,im_size,im_size) # chaning seq_image = seq_image.reshape(3,16,im_size,im_size) TO seq_image = seq_image.reshape(3,6,im_size,im_size) ---> now 3\n",
        "        count=0\n",
        "        return seq_image,decoder[label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msB4umEmPxj6",
        "outputId": "4e5b50fb-03d2-477c-c905-10d0de316436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "im_size = 128\n",
        "mean = [0.4889, 0.4887, 0.4891]\n",
        "std = [0.2074, 0.2074, 0.2074]\n",
        "\n",
        "\n",
        "train_transforms= transforms.Compose([\n",
        "        transforms.Resize(size=(128, 128)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "train_data = video_dataset(id,sequence_length = 16,transform = train_transforms)\n",
        "train_loader = DataLoader(train_data,batch_size = 32,num_workers = 4 ,shuffle = True)    \n",
        "dataloaders = {'train':train_loader}\n",
        "\n",
        "\n",
        "#train_transforms = transforms.Compose([\n",
        "#                                        transforms.Resize((im_size,im_size)),\n",
        "#                                        transforms.RandomHorizontalFlip(),\n",
        "#                                        transforms.RandomRotation(degrees=10),\n",
        "#                                        transforms.ToTensor(),\n",
        "#                                        transforms.Normalize(mean,std)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbsNWvqLvsSR"
      },
      "outputs": [],
      "source": [
        "from model import resnet50\n",
        "model = resnet50(class_num=345).to('cuda')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqyU-0k67-N_"
      },
      "outputs": [],
      "source": [
        "from clr import *\n",
        "device = 'cuda'\n",
        "cls_criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum = 0.9,weight_decay = 1e-4)\n",
        "num_epochs = 60\n",
        "onecyc = OneCycle(len(train_loader)*num_epochs,1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E-llvrMLc4d"
      },
      "outputs": [],
      "source": [
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybCCnE-T8GzU",
        "outputId": "713a788d-7371-4c1a-b841-5e64d85892ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch 0 is present\n",
            " epoch 1 is present\n",
            " epoch 2 is present\n",
            " epoch 3 is present\n",
            " epoch 4 is present\n",
            " epoch 5 is present\n",
            " epoch 6 is present\n",
            " epoch 7 is present\n",
            " epoch 8 is present\n",
            " epoch 9 is present\n",
            " epoch 10 is present\n",
            " epoch 11 is present\n",
            " epoch 12 is present\n",
            " epoch 13 is present\n",
            " epoch 14 is present\n",
            " epoch 15 is present\n",
            " epoch 16 is present\n",
            " epoch 17 is present\n",
            " epoch 18 is present\n",
            " epoch 19 is present\n",
            " epoch 20 is present\n",
            " epoch 21 is present\n",
            " epoch 22 is present\n",
            " epoch 23 is present\n",
            " epoch 24 is present\n",
            " epoch 25 is present\n",
            " epoch 26 is present\n",
            " epoch 27 is present\n",
            " epoch 28 is present\n",
            " epoch 29 is present\n",
            " epoch 30 is present\n",
            " epoch 31 is present\n",
            " epoch 32 is present\n",
            " epoch 33 is present\n",
            " epoch 34 is present\n",
            " epoch 35 is present\n",
            " epoch 36 is present\n",
            " epoch 37 is present\n",
            " epoch 38 is present\n",
            " epoch 39 is present\n",
            " epoch 40 is present\n",
            " epoch 41 is present\n",
            " epoch 42 is present\n",
            " epoch 43 is present\n",
            " epoch 44 is present\n",
            " epoch 45 is present\n",
            " epoch 46 is present\n",
            " epoch 47 is present\n",
            " epoch 48 is present\n",
            " epoch 49 is present\n",
            " epoch 50 is present\n",
            " epoch 51 is present\n",
            " epoch 52 is present\n",
            " epoch 53 is present\n",
            " epoch 54 is present\n",
            " epoch 55 is present\n",
            " epoch 56 is present\n",
            " epoch 57 is present\n",
            " epoch 58 is present\n",
            " epoch 59 is present\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "#This code is to append Loss and Accuray to plot them lateer--------------------------\n",
        "def append_new_line(file_name, text_to_append):\n",
        "    \"\"\"Append given text as a new line at the end of file\"\"\"\n",
        "    # Open the file in append & read mode ('a+')\n",
        "    with open(file_name, \"a+\") as file_object:\n",
        "        # Move read cursor to the start of file.\n",
        "        file_object.seek(0)\n",
        "        # If file is not empty then append '\\n'\n",
        "        data = file_object.read(100)\n",
        "        if len(data) > 0:\n",
        "            file_object.write(\"\\n\")\n",
        "        # Append text at the end of file\n",
        "        file_object.write(text_to_append)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#os.makedirs('/content/drive/MyDrive/sign_Weights2',exist_ok = True)\n",
        "if not (os.path.exists('/content/drive/MyDrive/sign_Weights5')):\n",
        "    os.makedirs('/content/drive/MyDrive/sign_Weights5',exist_ok = True)\n",
        "from torch.autograd import Variable\n",
        "iteration = 0\n",
        "acc_all = list()\n",
        "loss_all = list()\n",
        "\n",
        "\n",
        "#model.load_state_dict(torch.load(PATH))\n",
        "    \n",
        "check =0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    if (os.path.exists('/content/drive/MyDrive/sign_Weights5/c3d_{}.h5'.format(epoch))):\n",
        "        print(\" epoch\" , epoch , \"is present\")\n",
        "        check=1\n",
        "        continue\n",
        "    #torch.load('/content/drive/MyDrive/sign_Weights2/c3d_{}.h5'.format(epoch))\n",
        "    if (check==1):\n",
        "        print(\"Loading saved model\")\n",
        "        #model =  resnet50(class_num=345).to('cuda') \n",
        "        #model.load_state_dict(torch.load('/content/drive/MyDrive/sign_Weights2/c3d_{}.h5'.format(epoch-1) ))\n",
        "        #model.eval()\n",
        "\n",
        "\n",
        "        model = resnet50(class_num=345).to('cuda') \n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum = 0.9,weight_decay = 1e-4)\n",
        "        checkpoint = torch.load('/content/drive/MyDrive/sign_Weights5/c3d_{}.h5'.format(epoch-1) )\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        loss = checkpoint['loss']\n",
        "\n",
        "        model.train()\n",
        "        check=0\n",
        "# - or -\n",
        "        #model.train()\n",
        "       \n",
        "    #torch.eval()\n",
        "    #model = TempModel()\n",
        "#model.load_state_dict(torch.load(file_path))\n",
        "#model.eval()\n",
        "    print('')\n",
        "    print(f\"--- Epoch {epoch} ---\")\n",
        "    phase1 = dataloaders.keys()\n",
        "    for phase in phase1:\n",
        "       # torch.load  \n",
        "        print('')\n",
        "        print(f\"--- Phase {phase} ---\")\n",
        "        epoch_metrics = {\"loss\": [], \"acc\": []}\n",
        "        \n",
        "        for batch_i, (X, y) in enumerate(dataloaders[phase]):\n",
        "            #iteration = iteration+1\n",
        "            image_sequences = Variable(X.to(device), requires_grad=True)\n",
        "            labels = Variable(y.to(device), requires_grad=False)\n",
        "            optimizer.zero_grad()\n",
        "            #model.lstm.reset_hidden_state()\n",
        "            predictions = model(image_sequences)\n",
        "            loss = cls_criterion(predictions, labels)\n",
        "            acc = 100 * (predictions.detach().argmax(1) == labels).cpu().numpy().mean()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_metrics[\"loss\"].append(loss.item())\n",
        "            epoch_metrics[\"acc\"].append(acc)\n",
        "            if(phase=='train'):\n",
        "                lr,mom = onecyc.calc()\n",
        "                update_lr(optimizer, lr)\n",
        "                update_mom(optimizer, mom)\n",
        "            batches_done = epoch * len(dataloaders[phase]) + batch_i\n",
        "            batches_left = num_epochs * len(dataloaders[phase]) - batches_done\n",
        "            sys.stdout.write(\n",
        "                    \"\\r[Epoch %d/%d] [Batch %d/%d] [Loss: %f (%f), Acc: %.2f%% (%.2f%%)]\"\n",
        "                    % (\n",
        "                        epoch,\n",
        "                        num_epochs,\n",
        "                        batch_i,\n",
        "                        len(dataloaders[phase]),\n",
        "                        loss.item(),\n",
        "                        np.mean(epoch_metrics[\"loss\"]),\n",
        "                        acc,\n",
        "                        np.mean(epoch_metrics[\"acc\"]),\n",
        "                    )\n",
        "                )\n",
        "\n",
        "                # Empty cache\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "            \n",
        "        print('')\n",
        "        print('{} , acc: {}'.format(phase,np.mean(epoch_metrics[\"acc\"])))\n",
        "        #torch.save(model.state_dict(),'/content/drive/MyDrive/sign_Weights2/c3d_{}.h5'.format(epoch))\n",
        "\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss}, '/content/drive/MyDrive/sign_Weights5/c3d_{}.h5'.format(epoch))\n",
        "\n",
        "\n",
        "\n",
        "        if(phase=='train'):\n",
        "          \n",
        "          acc_all.append(np.mean(epoch_metrics[\"acc\"]))\n",
        "          loss_all.append(np.mean(epoch_metrics[\"loss\"]))\n",
        "          append_new_line('/content/drive/MyDrive/sign_Weights5/losslist.txt',str(np.mean(epoch_metrics[\"loss\"])))\n",
        "          append_new_line('/content/drive/MyDrive/sign_Weights5/acclist.txt',str(np.mean(epoch_metrics[\"acc\"])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoXZ08iHXbD2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7eaac05-b181-48b5-a656-6fe958ae0c4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5509752490941215,\n",
              " 1.5066994937027203,\n",
              " 1.5412968765286839,\n",
              " 1.4979738010203136,\n",
              " 1.5038245381677853,\n",
              " 1.4676428901798584,\n",
              " 1.406291732455001,\n",
              " 1.4469075733247925]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "loss_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrAzJ0DcNA5L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "14d93c96-63f5-483b-c6db-e2bee129baaa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0c793b31830d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtxt_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/sign_Weights4/losslist.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mfile_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxt_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#print(\"The file content are: \", file_content)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/sign_Weights4/losslist.txt'"
          ]
        }
      ],
      "source": [
        "\n",
        "#============DONT UNCOMMENT==================\n",
        "\n",
        "'''def append_new_line(file_name, text_to_append):\n",
        "    \"\"\"Append given text as a new line at the end of file\"\"\"\n",
        "    # Open the file in append & read mode ('a+')\n",
        "    with open(file_name, \"a+\") as file_object:\n",
        "        # Move read cursor to the start of file.\n",
        "        file_object.seek(0)\n",
        "        # If file is not empty then append '\\n'\n",
        "        data = file_object.read(100)\n",
        "        if len(data) > 0:\n",
        "            file_object.write(\"\\n\")\n",
        "        # Append text at the end of file\n",
        "        file_object.write(text_to_append)\n",
        "\n",
        "'''\n",
        "  \n",
        "\n",
        "\n",
        "txt_file = open(\"/content/drive/MyDrive/sign_Weights4/losslist.txt\", \"r\")\n",
        "file_content = txt_file.read()\n",
        "#print(\"The file content are: \", file_content)\n",
        "\n",
        "content_list = file_content.split(\"\\n\")\n",
        "txt_file.close()\n",
        "#print(\"The list is: \", content_list)\n",
        "accuracy_array=list()\n",
        "for i in content_list:\n",
        "    accuracy_array.append(float(i))\n",
        "print(\"Accuracy list is: \", accuracy_array)\n",
        "\n",
        "\n",
        "txt_file = open(\"/content/drive/MyDrive/sign_Weights4/acclist.txt\", \"r\")\n",
        "file_content = txt_file.read()\n",
        "#print(\"The file content are: \", file_content)\n",
        "\n",
        "content_list = file_content.split(\"\\n\")\n",
        "txt_file.close()\n",
        "#print(\"The list is: \", content_list)\n",
        "loss_array=list()\n",
        "for i in content_list:\n",
        "    loss_array.append(float(i))\n",
        "print(\"Loss list is: \", loss_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUFj04OitQER"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sH7XMOAjV7DH"
      },
      "outputs": [],
      "source": [
        "def error_plot(loss):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(loss)\n",
        "    plt.title(\"Training loss plot\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "def acc_plot(acc):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(acc)\n",
        "    plt.title(\"Training accuracy plot\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dybBWSyyWZfY"
      },
      "outputs": [],
      "source": [
        "\n",
        "acc_plot(accuracy_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtVNjFyeWVrd"
      },
      "outputs": [],
      "source": [
        "error_plot(loss_array)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70Xj1EBKM1CW"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "id = list()\n",
        "count =0\n",
        "path = '/content/drive/MyDrive/excuse'\n",
        "for i in os.listdir(path):\n",
        "  p1 = os.path.join(path,i)\n",
        "  for j in os.listdir(p1):\n",
        "    p2 = os.path.join(p1,j)\n",
        "    id.append((i,p2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9A1Us_VIURBj"
      },
      "outputs": [],
      "source": [
        "from clr import *\n",
        "device = 'cuda'\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWCOGn1nzNny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d403ca9-a254-4006-fefe-0b2c9cb2d538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "im_size = 128\n",
        "mean = [0.4889, 0.4887, 0.4891]\n",
        "std = [0.2074, 0.2074, 0.2074]\n",
        "\n",
        "\n",
        "test_transforms= transforms.Compose([\n",
        "        transforms.Resize(size=(128, 128)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "test_data = video_dataset(id,sequence_length = 16,transform = test_transforms)\n",
        "test_loader = DataLoader(test_data,batch_size = 64,num_workers = 4 ,shuffle = True)    \n",
        "testdataloaders = {'test':test_loader}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#test_loader = DataLoader(test_data,batch_size = 32,num_workers = 4 ,shuffle = True)    \n",
        "#dataloaders = {'train':test_loader}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwsFZz_FPEUm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf38b56-d943-42fa-b9ed-c9157cdc91da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Phase test ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 345])\n",
            "\n",
            "test , acc: 80.0  on epoch  55\n",
            "\n",
            "--- Phase test ---\n",
            "torch.Size([5, 345])\n",
            "\n",
            "test , acc: 60.0  on epoch  56\n",
            "\n",
            "--- Phase test ---\n",
            "torch.Size([5, 345])\n",
            "\n",
            "test , acc: 80.0  on epoch  57\n",
            "\n",
            "--- Phase test ---\n",
            "torch.Size([5, 345])\n",
            "\n",
            "test , acc: 60.0  on epoch  58\n",
            "\n",
            "--- Phase test ---\n",
            "torch.Size([5, 345])\n",
            "\n",
            "test , acc: 40.0  on epoch  59\n"
          ]
        }
      ],
      "source": [
        "model = resnet50(class_num=345).to('cuda') \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum = 0.9,weight_decay = 1e-4)\n",
        "epoch = 60\n",
        "for i in range (55,epoch):\n",
        "  try:\n",
        "    checkpoint = torch.load('/content/drive/MyDrive/sign_Weights5/c3d_{}.h5'.format(i))\n",
        "  except:\n",
        "    continue\n",
        "  #checkpoint = torch.load('/content/drive/MyDrive/sign_Weights4/c3d_30.h5')\n",
        "\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  model.eval()\n",
        "\n",
        "\n",
        "  lab=[]\n",
        "  pre=[]\n",
        "\n",
        "  phase1 = testdataloaders.keys()\n",
        "  for phase in phase1:\n",
        "      # torch.load  \n",
        "      print('')\n",
        "      print(f\"--- Phase {phase} ---\")\n",
        "      epoch_metrics = {\"loss\": [], \"acc\": []}\n",
        "      \n",
        "      for batch_i, (X, y) in enumerate(testdataloaders[phase]):\n",
        "          #iteration = iteration+1\n",
        "          image_sequences = Variable(X.to(device), requires_grad=True)\n",
        "          labels = Variable(y.to(device), requires_grad=False)\n",
        "          \n",
        "          #model.lstm.reset_hidden_state()\n",
        "          predictions = model(image_sequences)\n",
        "          print(predictions.shape)\n",
        "\n",
        "          loss = cls_criterion(predictions, labels)\n",
        "          #pre.append(predictions.detach().argmax(1))\n",
        "          #lab.append(lab)\n",
        "          acc = 100 * (predictions.detach().argmax(1) == labels).cpu().numpy().mean()\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          epoch_metrics[\"loss\"].append(loss.item())\n",
        "          epoch_metrics[\"acc\"].append(acc)\n",
        "              # Empty cache\n",
        "          \n",
        "          \n",
        "      print('')\n",
        "      print('{} , acc: {}'.format(phase,np.mean(epoch_metrics[\"acc\"])) , \" on epoch \" , i)\n",
        "      #torch.save(model.state_dict(),'/content/drive/MyDrive/sign_Weights2/c3d_{}.h5'.format(epoch))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cbxCy5tOwOU"
      },
      "outputs": [],
      "source": [
        "print(pre)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrmDY_SXiF0I"
      },
      "outputs": [],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWnpXP0miuWq"
      },
      "outputs": [],
      "source": [
        "predictions.detach().argmax(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gADfU_7Ci2wU"
      },
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5qgMJuWi9w5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "zeeshan.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}